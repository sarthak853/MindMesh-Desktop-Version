import { NextRequest, NextResponse } from 'next/server'
import { getCurrentUser } from '@/lib/auth'
import { SSRDocumentRepository } from '@/lib/repositories/document-ssr'
import { cache } from '@/lib/cache'

const documentRepository = new SSRDocumentRepository()

export async function POST(request: NextRequest) {
  try {
    const user = await getCurrentUser()

    if (!user) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
    }

    const formData = await request.formData()
    const file = formData.get('file') as File

    if (!file) {
      return NextResponse.json({ error: 'No file provided' }, { status: 400 })
    }

    // Validate file type
    const validTypes = [
      'application/pdf',
      'text/plain',
      'text/markdown',
      'application/msword',
      'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
    ]

    const isValidType = validTypes.includes(file.type) ||
      file.name.endsWith('.md') ||
      file.name.endsWith('.txt')

    if (!isValidType) {
      return NextResponse.json(
        { error: 'Invalid file type. Supported: PDF, TXT, MD, DOC, DOCX' },
        { status: 400 }
      )
    }

    // Validate file size (10MB limit)
    if (file.size > 10 * 1024 * 1024) {
      return NextResponse.json(
        { error: 'File too large. Maximum size is 10MB' },
        { status: 400 }
      )
    }

    // Extract text content based on file type
    let content = ''
    let fileUrl = ''

    if (file.type === 'text/plain' || file.name.endsWith('.txt') || file.name.endsWith('.md')) {
      content = await file.text()
    } else if (file.type === 'application/pdf') {
      // For PDF files, we would typically use a library like pdf-parse
      // For now, we'll create a placeholder
      content = `PDF Document: ${file.name}\n\n[PDF content would be extracted here using a PDF parsing library]`

      // In a real implementation, you would:
      // 1. Save the file to storage (AWS S3, etc.)
      // 2. Extract text using pdf-parse or similar
      // 3. Store the file URL
      fileUrl = `/uploads/${Date.now()}-${file.name}`
    } else {
      // For DOC/DOCX files, you would use libraries like mammoth
      content = `Document: ${file.name}\n\n[Document content would be extracted here using appropriate parsing library]`
      fileUrl = `/uploads/${Date.now()}-${file.name}`
    }

    // Create document record
    const document = await documentRepository.create({
      userId: user.id,
      title: file.name.replace(/\.[^/.]+$/, ''), // Remove file extension
      content,
      type: getDocumentType(file),
      fileUrl: fileUrl || undefined,
      embeddings: [], // Would be generated by AI service
      metadata: {
        originalFileName: file.name,
        fileSize: file.size,
        mimeType: file.type,
        uploadedAt: new Date(),
      },
    })

    // Clear user documents cache
    await cache.del(cache.keys.userDocuments(user.id))

    // TODO: Generate embeddings asynchronously
    // This would typically be done in a background job
    // generateEmbeddings(document.id, content)

    return NextResponse.json({
      document,
      message: 'Document uploaded successfully'
    }, { status: 201 })

  } catch (error) {
    console.error('Error uploading document:', error)
    return NextResponse.json(
      { error: 'Failed to upload document' },
      { status: 500 }
    )
  }
}

function getDocumentType(file: File): string {
  if (file.type === 'application/pdf') return 'pdf'
  if (file.type === 'text/plain' || file.name.endsWith('.txt')) return 'text'
  if (file.name.endsWith('.md')) return 'text'
  if (file.type.includes('word')) return 'text'
  return 'text'
}