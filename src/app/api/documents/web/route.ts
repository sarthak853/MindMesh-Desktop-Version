import { NextRequest, NextResponse } from 'next/server'
import { getCurrentUser } from '@/lib/auth'
import { DocumentRepository } from '@/lib/repositories/document'
import { cache } from '@/lib/cache'

const documentRepository = new DocumentRepository()

export async function POST(request: NextRequest) {
  try {
    const user = await getCurrentUser()
    
    if (!user) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
    }

    const body = await request.json()
    const { url } = body

    if (!url || typeof url !== 'string') {
      return NextResponse.json({ error: 'URL is required' }, { status: 400 })
    }

    // Validate URL format
    try {
      new URL(url)
    } catch {
      return NextResponse.json({ error: 'Invalid URL format' }, { status: 400 })
    }

    // Fetch content from URL
    let content = ''
    let title = ''
    let metadata: any = {}

    try {
      const response = await fetch(url, {
        headers: {
          'User-Agent': 'MindMesh Bot 1.0',
        },
        // Add timeout
        signal: AbortSignal.timeout(10000), // 10 seconds
      })

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`)
      }

      const contentType = response.headers.get('content-type') || ''
      
      if (contentType.includes('text/html')) {
        const html = await response.text()
        
        // Basic HTML parsing to extract title and content
        // In a real implementation, you'd use a proper HTML parser like cheerio
        const titleMatch = html.match(/<title[^>]*>([^<]+)<\/title>/i)
        title = titleMatch ? titleMatch[1].trim() : new URL(url).hostname

        // Extract text content (very basic implementation)
        // Remove HTML tags and scripts
        content = html
          .replace(/<script[^>]*>[\s\S]*?<\/script>/gi, '')
          .replace(/<style[^>]*>[\s\S]*?<\/style>/gi, '')
          .replace(/<[^>]+>/g, ' ')
          .replace(/\s+/g, ' ')
          .trim()

        // Limit content length
        if (content.length > 50000) {
          content = content.substring(0, 50000) + '...'
        }

        metadata = {
          url,
          contentType,
          fetchedAt: new Date(),
          domain: new URL(url).hostname,
        }
      } else if (contentType.includes('text/plain')) {
        content = await response.text()
        title = new URL(url).pathname.split('/').pop() || new URL(url).hostname
        
        metadata = {
          url,
          contentType,
          fetchedAt: new Date(),
          domain: new URL(url).hostname,
        }
      } else {
        return NextResponse.json(
          { error: 'Unsupported content type. Only HTML and plain text are supported.' },
          { status: 400 }
        )
      }

    } catch (error) {
      console.error('Error fetching URL:', error)
      return NextResponse.json(
        { error: 'Failed to fetch content from URL. Please check the URL and try again.' },
        { status: 400 }
      )
    }

    if (!content.trim()) {
      return NextResponse.json(
        { error: 'No content could be extracted from the URL' },
        { status: 400 }
      )
    }

    // Create document record
    const document = await documentRepository.create({
      userId: user.id,
      title,
      content,
      type: 'web',
      embeddings: [], // Would be generated by AI service
      metadata,
    })

    // Clear user documents cache
    await cache.del(cache.keys.userDocuments(user.id))

    // TODO: Generate embeddings asynchronously
    // generateEmbeddings(document.id, content)

    return NextResponse.json({ 
      document,
      message: 'Web content imported successfully'
    }, { status: 201 })

  } catch (error) {
    console.error('Error importing web content:', error)
    return NextResponse.json(
      { error: 'Failed to import web content' },
      { status: 500 }
    )
  }
}